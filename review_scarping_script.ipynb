{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMAZON CUSTOMER REVIEW SCRAPING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents the data gathering process in the study of Amazon customer satisfaction using sentiment analysis. Through this analysis, we aim to add meaningful perspectives to the relationship between customer sentiment and satisfaction contribute to the broader understanding of customer feedback and their impact on business performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE DATA GATHERING PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data gathering process involves the use of Python programming language to scrap customer reviews from the Amazon's e-commerce platform. This was achieve using the Selenium library, beginning with the installation of Selenium chrome web driver on a local machine.\n",
    "\n",
    "The required libraries for the analysis were then imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import re \n",
    "from selenium.common.exceptions import StaleElementReferenceException\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the ASIN dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture customer reviews from different product categories and across different years, a list of Amazon Standard Identification Number (ASIN) was used. ASIN is a unique block of 10 characters used exclusively within Amazon's system to identify products.  The list of ASINs used was downloaded from the Internet Archive, which contains the ASINs of more than 75 million Amazon products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB: The next code cell will take few minutes to run  because it processes a large file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the asin file\n",
    "products = pd.read_csv('asins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75115473, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape of the dataframe\n",
    "products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have over 75 million ASINs for different Amazon products in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00000IGGJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00005JNBQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00006KGC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00006KGC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00007EPJ6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin\n",
       "0  B00000IGGJ\n",
       "1  B00005JNBQ\n",
       "2  B00006KGC0\n",
       "3  B00006KGC2\n",
       "4  B00007EPJ6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the head of the dataframe\n",
    "products.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next is to create and an initially empty dataframe to store the customer review data scrapped from Amazon's e-commerce platform. While the DataFrame starts off empty, it gradually fills up with review data during subsequent iterations of the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Creating an empty DataFrame with the specified columns\\ncolumns = ['item', 'review', 'date', 'rating', 'review_word', 'item_url']\\ndata = pd.DataFrame(columns=columns)\\ndata\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This script is meant to run once at the start to create an empty DataFrame that will later be populated with customer review data.\n",
    "'''\n",
    "# Creating an empty DataFrame with the specified columns\n",
    "columns = ['item', 'review', 'date', 'rating', 'review_word', 'item_url']\n",
    "data = pd.DataFrame(columns=columns)\n",
    "data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, the dataframe is loaded and updated in the next iteration of the scraping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('amazon_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_word</th>\n",
       "      <th>item_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>My dvd</td>\n",
       "      <td>September 19, 2022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The movie was great</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>A true tale to follow</td>\n",
       "      <td>January 31, 2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The animation is quite clever and the story is...</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>Fast shipping</td>\n",
       "      <td>August 16, 2022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fast shipping. Good quality. Thank you</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>A Fun, Cynical Ride</td>\n",
       "      <td>January 9, 2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>More a cynical Disney film, the movie has no d...</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>A Disney Classic</td>\n",
       "      <td>April 4, 2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If you are a fan of Disney animation then you ...</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                item                 review  \\\n",
       "0  Alice in Wonderland (Disney Gold Classic Colle...                 My dvd   \n",
       "1  Alice in Wonderland (Disney Gold Classic Colle...  A true tale to follow   \n",
       "2  Alice in Wonderland (Disney Gold Classic Colle...          Fast shipping   \n",
       "3  Alice in Wonderland (Disney Gold Classic Colle...    A Fun, Cynical Ride   \n",
       "4  Alice in Wonderland (Disney Gold Classic Colle...       A Disney Classic   \n",
       "\n",
       "                 date  rating  \\\n",
       "0  September 19, 2022     5.0   \n",
       "1    January 31, 2019     5.0   \n",
       "2     August 16, 2022     5.0   \n",
       "3     January 9, 2019     4.0   \n",
       "4       April 4, 2019     5.0   \n",
       "\n",
       "                                         review_word  \\\n",
       "0                                The movie was great   \n",
       "1  The animation is quite clever and the story is...   \n",
       "2             Fast shipping. Good quality. Thank you   \n",
       "3  More a cynical Disney film, the movie has no d...   \n",
       "4  If you are a fan of Disney animation then you ...   \n",
       "\n",
       "                                            item_url  \n",
       "0  https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "1  https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "2  https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "3  https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "4  https://www.amazon.com/Alice-Wonderland-Disney...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10593, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to set the path for the ChromeDriver in the local machine and initialize the Chrome browser to allow for an automated interaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the ChromeDriver \n",
    "s = Service(\"C:\\\\Users\\\\akint\\\\Downloads\\\\chromedriver-win64\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service= s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to perform the actual scraping of the customer reviews. The script below will loop through the ASINs in the products DataFrame, visit the Amazon product page, and scrape the customer reviews. The reviews will be stored in the data DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B: The script in the next cell will open a new Chrome window and navigate to the Amazon website. To bypass human verification, the code displaced on the page needs to be typed correctly in the input box.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for product with asin: B00004R982\n",
      "Current data shape is  (10593, 6)\n",
      "THIS IS PAGE 1 -------------------\n",
      "review scrapped --------------- length: 10\n",
      "date scrapped --------------- length: 10\n",
      "rating scrapped --------------- length: 10\n",
      "review word scrapped --------------- length: 10\n",
      "item scrapped --------------- length: 10\n",
      "item_url scrapped --------------- length: 265\n",
      "10 10 10 10 10\n",
      "(10, 6)\n",
      "(10603, 6)\n",
      "                 item               review             date rating  \\\n",
      "0  Revolver: New Spin  Dyer Buyers BEWARE!  January 2, 2001    2.0   \n",
      "1  Revolver: New Spin  Something Different   March 14, 2014    4.0   \n",
      "\n",
      "                                         review_word  \\\n",
      "0  There are a few good cuts on this album, the k...   \n",
      "1  I was browsing around looking for something di...   \n",
      "\n",
      "                                            item_url  \n",
      "0  https://www.amazon.com/Revolver-Dyer-Good-Time...  \n",
      "1  https://www.amazon.com/Revolver-Dyer-Good-Time...  \n",
      "Revolver: New Spin reviews scraped scrapping completed\n",
      "Searching for product with asin: B00004R990\n",
      "Product not found\n"
     ]
    }
   ],
   "source": [
    "# Looping through the ASINs in the DataFrame\n",
    "for asin in products['asin'].loc[2024: 2025]:\n",
    "    # Then navigate to the specified URL and maximize the window\n",
    "    driver.get('https://www.amazon.com/')\n",
    "    driver.maximize_window()\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Search for the product\n",
    "    time.sleep(3)\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "    search.send_keys(asin)\n",
    "    time.sleep(10)\n",
    "    print('Searching for product with asin:', asin)\n",
    "\n",
    "    # Click on the search button\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\").click()\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    # click on the product\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]/div[2]/div/div/span/div/div\").click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # if the url exits, then proceed with this script\n",
    "\n",
    "        # get the url of the item\n",
    "        time.sleep(2)\n",
    "        item_url = driver.current_url\n",
    "\n",
    "        # click on US reviews\n",
    "        driver.find_element(By.XPATH, \"//div[@data-hook='reviews-medley-footer']//div//a[@data-hook='see-all-reviews-link-foot']\").click()\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        #data = pd.DataFrame(columns=['review', 'date', 'rating', 'review_word', 'item'])\n",
    "\n",
    "\n",
    "        # create empty lists to store the reviews, dates, ratings, review words, and items\n",
    "\n",
    "        item = []\n",
    "        review = []\n",
    "        date = []\n",
    "        rating = []\n",
    "        review_word = []\n",
    "\n",
    "        page =1\n",
    "        while True:\n",
    "            item = []\n",
    "            review = []\n",
    "            date = []\n",
    "            rating = []\n",
    "            review_word = []\n",
    "            item_urls = []\n",
    "\n",
    "            print('Current data shape is ', data.shape)\n",
    "            print(f'THIS IS PAGE {page} -------------------')\n",
    "\n",
    "            # Then extract the reviews\n",
    "            reviews = driver.find_elements(By.XPATH, \"//a[@data-hook='review-title']\")\n",
    "            # Iterate through each <a> element\n",
    "            for a in reviews:\n",
    "                # Find all <span> elements within the current <a> element\n",
    "                time.sleep(2)\n",
    "                try:\n",
    "                    span_elements = a.find_elements(By.XPATH, \".//span\")\n",
    "                    if span_elements:\n",
    "                        # Extract the text of the last <span> element\n",
    "                        last_span_text = span_elements[-1].text\n",
    "                        review.append(last_span_text)\n",
    "                except StaleElementReferenceException:\n",
    "                    continue\n",
    "            print('review scrapped --------------- length:', len(review))\n",
    "\n",
    "            # Now we will extract the dates\n",
    "            for i in range(1, 15):\n",
    "                try:\n",
    "                    dates = driver.find_elements(By.XPATH, f\"//div[{i}]/div[3]/div/div/div/div/span\")\n",
    "                    for date_item in dates:\n",
    "                        date.append(date_item.text)\n",
    "                        date = [word for word in date if word not in ['Helpful', 'Report']]\n",
    "                        date = [data for data in date if 'person' not in data]\n",
    "                        date = [data for data in date if 'people' not in data]\n",
    "                        date = [data.replace('Reviewed in the United States on ', '') for data in date]\n",
    "                except StaleElementReferenceException:\n",
    "                    continue\n",
    "            \n",
    "            print('date scrapped --------------- length:', len(date))\n",
    "\n",
    "            # Extract the ratings\n",
    "            for i in range(1, 15):\n",
    "                try:\n",
    "                    ratings = driver.find_elements(By.XPATH, f\"//div[{i}]/div/div/div[2]/a/i/span[1]\")\n",
    "                    for rating_item in ratings:\n",
    "                        ratings_html = rating_item.get_attribute('outerHTML')\n",
    "                        rates = re.search(r'\\d+\\.\\d+', str(ratings_html)).group()\n",
    "                        rating.append(rates)\n",
    "                        time.sleep(2)\n",
    "                except StaleElementReferenceException:\n",
    "                    continue\n",
    "            if date == []:\n",
    "                rating = []\n",
    "            print('rating scrapped --------------- length:', len(rating))\n",
    "\n",
    "            # Extract the review words\n",
    "            for i in range(1, 15):\n",
    "                try:\n",
    "                    review_words = driver.find_elements(By.XPATH, f\"//body/div/div/div/div/div/div/div/div/div/div[{i}]/div[1]/div[1]/div[4]/span[1]/span[1]\")\n",
    "                    for review_word_item in review_words:\n",
    "                        if review_word_item.text != \"\" :\n",
    "                                review_word.append(review_word_item.text)\n",
    "                                if date == []:\n",
    "                                    review_word = []\n",
    "                                \n",
    "                        time.sleep(2)\n",
    "                except StaleElementReferenceException:\n",
    "                    continue\n",
    "            print('review word scrapped --------------- length:', len(review_word))\n",
    "\n",
    "            items = driver.find_element(By.XPATH, \"//a[@data-hook='product-link']\")\n",
    "            for i in range(1, len(date)+1):\n",
    "                item.append(items.text)\n",
    "            if date == []:\n",
    "                item = []\n",
    "            print('item scrapped --------------- length:', len(item))\n",
    "\n",
    "            #obtain the url of the item\n",
    "            for i in range(1, len(date)+1):\n",
    "                item_urls.append(item_url)\n",
    "            print('item_url scrapped --------------- length:', len(item_url))\n",
    "            \n",
    "            print(len(review) ,len(date), len(rating), len(review_word), len(item))\n",
    "\n",
    "\n",
    "            if len(date) != len(rating) != len(review_word):\n",
    "                print('The length of the lists are not equal')\n",
    "                break\n",
    "            else:\n",
    "                # Append the scraped data to the DataFrame\n",
    "                df = pd.DataFrame({'item': item, 'review': review, 'date': date, 'rating': rating, 'review_word': review_word, 'item_url': item_url})\n",
    "                two = [df, data]\n",
    "                data = pd.concat(two)\n",
    "                print(df.shape)\n",
    "                print(data.shape)\n",
    "                data\n",
    "                print(data.head(2))\n",
    "                time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                if page == 1:\n",
    "                    time.sleep(2)\n",
    "                    driver.find_element(By.XPATH, \"//div[@role='navigation']//ul//li//a\").click()\n",
    "                    time.sleep(4)\n",
    "                else:\n",
    "                    time.sleep(2)\n",
    "                    driver.find_element(By.XPATH, \"//span[@data-action='reviews:page-action']//li[2]//a[1]\").click()\n",
    "                    time.sleep(4)\n",
    "                page += 1\n",
    "            except:\n",
    "                page = 'Last page'\n",
    "                print(f'{items.text} reviews scraped scrapping completed')\n",
    "                break\n",
    "\n",
    "    except:\n",
    "        print('Product not found')\n",
    "        continue\n",
    "\n",
    "    #save to csv file\n",
    "    data.to_csv('amazon_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_word</th>\n",
       "      <th>item_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>My dvd</td>\n",
       "      <td>September 19, 2022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The movie was great</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>A true tale to follow</td>\n",
       "      <td>January 31, 2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The animation is quite clever and the story is...</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>Fast shipping</td>\n",
       "      <td>August 16, 2022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fast shipping. Good quality. Thank you</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>A Fun, Cynical Ride</td>\n",
       "      <td>January 9, 2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>More a cynical Disney film, the movie has no d...</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice in Wonderland (Disney Gold Classic Colle...</td>\n",
       "      <td>A Disney Classic</td>\n",
       "      <td>April 4, 2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If you are a fan of Disney animation then you ...</td>\n",
       "      <td>https://www.amazon.com/Alice-Wonderland-Disney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10588</th>\n",
       "      <td>Gotta Get the Groove Back</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>February 13, 2018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This was an excellent cd with all his greatest...</td>\n",
       "      <td>https://www.amazon.com/Gotta-Groove-Back-JOHNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10589</th>\n",
       "      <td>Gotta Get the Groove Back</td>\n",
       "      <td>Hot hot hot!</td>\n",
       "      <td>December 19, 2013</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Who doesn't like \"big head hundreds\" ??? This ...</td>\n",
       "      <td>https://www.amazon.com/Gotta-Groove-Back-JOHNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10590</th>\n",
       "      <td>Gotta Get the Groove Back</td>\n",
       "      <td>Glad I purchased it because I love the entire cd</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is one cd I had not heard completely. Gla...</td>\n",
       "      <td>https://www.amazon.com/Gotta-Groove-Back-JOHNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10591</th>\n",
       "      <td>Gotta Get the Groove Back</td>\n",
       "      <td>NaN</td>\n",
       "      <td>April 11, 2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Replacing damaged album</td>\n",
       "      <td>https://www.amazon.com/Gotta-Groove-Back-JOHNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10592</th>\n",
       "      <td>Gotta Get the Groove Back</td>\n",
       "      <td>this is a must have CD</td>\n",
       "      <td>June 11, 2014</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Proud to own it a very good cd with great song...</td>\n",
       "      <td>https://www.amazon.com/Gotta-Groove-Back-JOHNN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10593 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    item  \\\n",
       "0      Alice in Wonderland (Disney Gold Classic Colle...   \n",
       "1      Alice in Wonderland (Disney Gold Classic Colle...   \n",
       "2      Alice in Wonderland (Disney Gold Classic Colle...   \n",
       "3      Alice in Wonderland (Disney Gold Classic Colle...   \n",
       "4      Alice in Wonderland (Disney Gold Classic Colle...   \n",
       "...                                                  ...   \n",
       "10588                          Gotta Get the Groove Back   \n",
       "10589                          Gotta Get the Groove Back   \n",
       "10590                          Gotta Get the Groove Back   \n",
       "10591                          Gotta Get the Groove Back   \n",
       "10592                          Gotta Get the Groove Back   \n",
       "\n",
       "                                                 review                date  \\\n",
       "0                                                My dvd  September 19, 2022   \n",
       "1                                 A true tale to follow    January 31, 2019   \n",
       "2                                         Fast shipping     August 16, 2022   \n",
       "3                                   A Fun, Cynical Ride     January 9, 2019   \n",
       "4                                      A Disney Classic       April 4, 2019   \n",
       "...                                                 ...                 ...   \n",
       "10588                                        Five Stars   February 13, 2018   \n",
       "10589                                      Hot hot hot!   December 19, 2013   \n",
       "10590  Glad I purchased it because I love the entire cd    December 3, 2015   \n",
       "10591                                               NaN      April 11, 2019   \n",
       "10592                            this is a must have CD       June 11, 2014   \n",
       "\n",
       "       rating                                        review_word  \\\n",
       "0         5.0                                The movie was great   \n",
       "1         5.0  The animation is quite clever and the story is...   \n",
       "2         5.0             Fast shipping. Good quality. Thank you   \n",
       "3         4.0  More a cynical Disney film, the movie has no d...   \n",
       "4         5.0  If you are a fan of Disney animation then you ...   \n",
       "...       ...                                                ...   \n",
       "10588     5.0  This was an excellent cd with all his greatest...   \n",
       "10589     5.0  Who doesn't like \"big head hundreds\" ??? This ...   \n",
       "10590     5.0  This is one cd I had not heard completely. Gla...   \n",
       "10591     4.0                            Replacing damaged album   \n",
       "10592     5.0  Proud to own it a very good cd with great song...   \n",
       "\n",
       "                                                item_url  \n",
       "0      https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "1      https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "2      https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "3      https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "4      https://www.amazon.com/Alice-Wonderland-Disney...  \n",
       "...                                                  ...  \n",
       "10588  https://www.amazon.com/Gotta-Groove-Back-JOHNN...  \n",
       "10589  https://www.amazon.com/Gotta-Groove-Back-JOHNN...  \n",
       "10590  https://www.amazon.com/Gotta-Groove-Back-JOHNN...  \n",
       "10591  https://www.amazon.com/Gotta-Groove-Back-JOHNN...  \n",
       "10592  https://www.amazon.com/Gotta-Groove-Back-JOHNN...  \n",
       "\n",
       "[10593 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at the data\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10593, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have successfully scraped the reviews of the products using the ASINs in the DataFrame. Now, the will update the 'amazon_reviews' file by saving the newly scrapped data to the file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv file\n",
    "data.to_csv('amazon_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
